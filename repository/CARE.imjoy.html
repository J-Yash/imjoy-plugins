<docs lang="markdown">
#CARE

Weigert et. al, Content-aware image restoration: pushing the limits of fluorescence microscopy, Nature Methods, 2018

[Paper on Nature Methods](https://www.nature.com/articles/s41592-018-0216-7)

This is a demo plugin ported from https://github.com/CSBDeep/CSBDeep/blob/master/examples/denoising2D_probabilistic/1_training.ipynb

</docs>

<config lang="json">
{
  "name": "CARE",
  "type": "native-python",
  "version": "0.1.2",
  "api_version": "0.1.2",
  "description": "This plugin demonstrate denoising using CARE",
  "tags": ["CPU", "GPU", "macOS CPU"],
  "ui": "",
  "inputs": null,
  "outputs": null,
  "flags": [],
  "icon": "extension",
  "env": {
      "CPU": "conda create -n care-cpu python=3.6.7", 
      "GPU": "conda create -n care-gpu python=3.6.7", 
      "macOS CPU": "conda create -n care-mac-cpu python=3.6.7"
  },
  "requirements": {
      "CPU": ["pip: tensorflow==1.8.0 Pillow csbdeep tifffile six"], 
      "GPU": ["pip: tensorflow-gpu==1.8.0 Pillow csbdeep tifffile six"], 
      "macOS CPU": ["pip: tensorflow==1.5.0 Pillow csbdeep tifffile six"]
  },
  "dependencies": ["oeway/ImJoy-Plugins:Im2Im-Dashboard"]
}
</config>

<script lang="python">
from __future__ import print_function, unicode_literals, absolute_import, division
import os
import asyncio
import random
import numpy as np
from tifffile import imread

import concurrent.futures
from imjoy import api
os.environ['CUDA_VISIBLE_DEVICES'] = "1"

import tensorflow as tf
import base64
from io import BytesIO
from PIL import Image

from keras.callbacks import Callback
from csbdeep.utils.plot_utils import to_color
from csbdeep.utils import download_and_extract_zip_file, axes_dict, plot_some, plot_history
from csbdeep.utils.tf import limit_gpu_memory
from csbdeep.io import load_training_data
from csbdeep.models import Config, CARE
from csbdeep.data import RawData, create_patches



api.log(str(os.environ))

if tf.test.gpu_device_name():
    api.log('Default GPU Devices: {}'.format(tf.test.gpu_device_name()))
else:
    api.log("No GPU device is avilable")

if not os.path.exists('data/tribolium.npz'):
    api.showStatus('Downloading files')
    download_and_extract_zip_file (
        url       = 'http://csbdeep.bioimagecomputing.com/example_data/tribolium.zip',
        targetdir = 'data',
    )

    raw_data = RawData.from_folder (
        basepath    = 'data/tribolium/train',
        source_dirs = ['low'],
        target_dir  = 'GT',
        axes        = 'ZYX',
    )

    api.showStatus('Creating patches')
    X, Y, XY_axes = create_patches (
        raw_data            = raw_data,
        patch_size          = (16,64,64),
        n_patches_per_image = 1024,
        save_file           = 'data/tribolium.npz',
    )

    api.log('patches:'+str(X.shape))

(X,Y), (X_val,Y_val), axes = load_training_data('data/tribolium.npz', validation_split=0.1, verbose=True)

api.log(str(X.shape))


y = imread('data/tribolium/test/GT/nGFP_0.1_0.2_0.5_20_14_late.tif')
x = imread('data/tribolium/test/low/nGFP_0.1_0.2_0.5_20_14_late.tif')


api.log('image size ='+ str(x.shape))
api.log('image axes ='+str(axes))

c = axes_dict(axes)['C']
n_channel_in, n_channel_out = X.shape[c], Y.shape[c]
#plt.figure(figsize=(12,5))
#plot_some(X_val[:5],Y_val[:5])
#plt.suptitle('5 example validation patches (top row: source, bottom row: target)');


def plot_tensors(dash, tensor_list, label, titles):
    # randomly select a Z
    index = np.random.randint(0, tensor_list[0].shape[0])
    image_list = [tensor[index, :,:] for tensor in tensor_list]
    displays = {}
    titles = titles or [ 'Tensor '+str(i) for i in range(len(image_list))]
    for i in range(len(image_list)):
        im = image_list[i]
        api.log(str(im.shape))

        im = im[ :,:]
        min = im.min()
        normalized_im = ((im-min)/(im.max()-min)*255)
        im = Image.fromarray(normalized_im.astype('uint8'))

        buffered = BytesIO()
        im.save(buffered, format="JPEG")
        img_str = base64.b64encode(buffered.getvalue()).decode('ascii')
        imgurl = 'data:image/png;base64,' + img_str
        displays[titles[i]] = imgurl
    dash.appendDisplay(label, displays)

class UpdateUI(Callback):
    def __init__(self, model, total_epoch, dash, config):
        self.total_epoch = total_epoch
        self.epoch = 0
        self.logs = {}
        self.dash = dash
        self.step = 0
        self.config = config
        self.m = model
        #self.gen = gen
    def on_batch_end(self, batch, logs):
        if batch % 10 == 0:
            self.logs = logs
            api.showStatus('training epoch:'+str(self.epoch)+'/'+str(self.total_epoch) + ' ' + str(logs))
            self.dash.updateCallback('onStep', self.step, {'loss': np.asscalar(logs['loss']), 'mse': np.asscalar(logs['mse'])})
        self.step += 1
    def on_epoch_end(self, epoch, logs):
        self.epoch = epoch
        self.logs = logs
        self.dash.updateCallback('onStep', self.step, {'val_loss': np.asscalar(logs['val_loss'])})
        api.showProgress(self.epoch/self.total_epoch*100)
        api.showStatus('training epoch:'+str(self.epoch)+'/'+str(self.total_epoch) + ' '+ str(logs))
        
        axes = 'ZYX'
        restored = self.m.predict(x, axes)
        # restored = self.m.predict(x, axes, n_tiles=(1,4,4))
        api.log(str(restored.shape) + str(x.shape))
        tensor_list = [restored, x, y]
        label = 'Step '+ str(self.step)
        titles = ["output", 'input', 'target']
        plot_tensors(self.dash, tensor_list, label, titles)

loop = asyncio.get_event_loop()
class ImJoyPlugin():
    def setup(self):
        print('setup in python')

    def train(self, config):
        asyncio.set_event_loop(loop)
        
        # api.alert('start training')
        api.log('running in thellop...')
        model = CARE(config, 'my_model', basedir='models')
        updateUI = UpdateUI(model, config.train_steps_per_epoch, self.dash, config)
        
        api.log('start training')
        
        model.prepare_for_training()
        model.callbacks.append(updateUI)
        history = model.train(X,Y, validation_data=(X_val,Y_val))
        print(sorted(list(history.history.keys())))
        api.log('training stoped')

    async def run(self, ctx):
        epochs = 30
        config = Config(axes, n_channel_in, n_channel_out, probabilistic=True, train_steps_per_epoch=epochs)
        print(config)
        self.dash = await api.createWindow(type="Im2Im-Dashboard", name="CARE Training", w=25, h=10, data={"display_mode": "all", 'metrics': ['loss', 'val_loss', 'mse'], 'callbacks': ['onStep']})
        await loop.run_in_executor(None, self.train, config)

api.export(ImJoyPlugin())
</script>
