
<docs lang="markdown">
# ANNA-PALM: deep learning massively accelerates super-resolution localization microscopy

Ouyang et al., Nat. Biotechnol. 2018, doi:10.1038/nbt.4106

Paper on Nature Biotechnology: https://rdcu.be/LGtc
</docs>

<config lang="json">
{
  "name": "ANNA-PALM",
  "type": "native-python",
  "version": "0.1.13",
  "api_version": "0.1.5",
  "description": "A plugin for training models with ANNA-PALM.",
  "tags": ["CPU", "GPU"],
  "ui": null,
  "inputs": null,
  "outputs": null,
  "icon": null,
  "env": {"CPU": ["conda create -n annapalm-cpu python=3.6"], "GPU": ["conda create -n annapalm-gpu python=3.6"]},
  "requirements": {
    "CPU": ["repo:https://github.com/imodpasteur/ANNA-PALM", "cmd:pip install -r ANNA-PALM/requirements.txt"],
    "GPU": ["repo:https://github.com/imodpasteur/ANNA-PALM", "pip: Pillow numpy==1.15.0 scipy matplotlib scikit-image tensorflow-gpu==1.8.0 gputil==1.4.0"]
  },
  "dependencies": ["oeway/ImJoy-Plugins:Im2Im-Dashboard","oeway/ImJoy-Plugins:ANNA-PALM-docs", "https://gist.githubusercontent.com/oeway/961c8d7abe24383d3ad6312669fe1d7c/raw/launchpad.imjoy.html"],
  "cover": "https://dl.dropbox.com/s/gja7uhjctell2nd/annapalm-0.1.9.gif"
  }
</config>

<script lang="python">
import sys
import os

sys.path.insert(0, 'ANNA-PALM')

if api.TAG == 'GPU':
    import GPUtil
    # Set CUDA_DEVICE_ORDER so the IDs assigned by CUDA match those from nvidia-smi
    os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"

    # Get the first available GPU
    DEVICE_ID_LIST = GPUtil.getFirstAvailable()
    api.log(f'Available GPUs: {DEVICE_ID_LIST}')
    if len(DEVICE_ID_LIST)<= 0:
        api.alert('No GPU available')
        raise Exception('No GPU available')

    DEVICE_ID = DEVICE_ID_LIST[0] # grab first element from list
    api.log(f'Set GPU id to : {DEVICE_ID}')
    # Set CUDA_VISIBLE_DEVICES to mask out all other GPUs than the first available device id
    os.environ["CUDA_VISIBLE_DEVICES"] = str(DEVICE_ID)

api.log(str(os.environ))


import sys
import tensorflow as tf
from AnetLib.options.train_options import Options
from AnetLib.models.models import create_model
from smlm_datasets import create_data_sources
import asyncio
import base64
from io import BytesIO
from PIL import Image
import concurrent.futures
from imjoy import api


default_workdir = './workdir'
opt = Options().parse(['--workdir=./tmp_predict'])
opt.model = 'a_net_tensorflow'
opt.fineSize = 512
opt.batchSize = 1
opt.dim_ordering = 'channels_last'
opt.display_freq = 500
opt.use_resize_conv = True
opt.norm_A = 'mean_std'
opt.norm_B = 'min_max[0,1]'
opt.lambda_A = 50
opt.input_nc = 2
opt.lr_nc = 1
opt.lr_scale = 1.0/4.0
opt.lambda_LR = 0
opt.control_nc = 1
opt.add_data_type_control = True
opt.add_lr_channel = 'pseudo'
opt.print_freq = 3
opt.display_freq = 1

if tf.test.gpu_device_name():
    api.log('Default GPU Devices: {}'.format(tf.test.gpu_device_name()))
else:
    api.log("No GPU device is avilable")
    if api.TAG == 'GPU':
        api.alert('No GPU device is avilable')

if os.path.exists('/imjoy/imjoy-paper'):
    ROOT_DIR = '/imjoy/imjoy-paper'
else:
    ROOT_DIR = ''

class ImJoyPlugin():
  async def setup(self):
    self.step = 0
    self.dialog = None
    #self.executor = concurrent.futures.ThreadPoolExecutor(
    #    max_workers=3,
    #)
    self.model = None

  def resume(self):
    api.alert('plugin process resumed')

  async def run(self, my):
    self.dialog = await api.showDialog(type='launchpad', data= [
            {'name': 'Load trained model', 'description': 'Load a pre-trained model', 'callback': self.load_model, 'img': 'https://img.icons8.com/ios-glyphs/48/000000/submit-progress.png'},
            #{'name': 'Train: simulated microtubules', 'description': 'Start training on simulated microtubules', 'callback': self.train_sim_tubulin, 'img': 'https://img.icons8.com/color/100/000000/gears.png'},
            #{'name': 'Predict: simulated microtubules', 'description': 'Predict simulated microtubule', 'callback': self.predict_sim_tubulin, 'img': 'https://img.icons8.com/color/96/000000/double-right.png'},
            {'name': 'Train: experimental microtubules', 'description': 'Start training on experimental microtubules', 'callback': self.train_csv, 'img': 'https://img.icons8.com/bubbles/100/000000/gears.png'},
            {'name': 'Predict: experimental microtubules', 'description': 'Predict experimental microtubules', 'callback': self.predict_csv, 'img': 'https://img.icons8.com/bubbles/100/000000/circled-chevron-right.png'},
            {'name': 'Documentation', 'description': 'Show documentation.', 'callback': self.show_docs, 'img': 'https://img.icons8.com/color/96/000000/help.png'},
        ]
    )

  async def show_docs(self):
    self.dialog.close()
    try:
        await this.win_docs.run({'data': {}})
    except:
        this.win_docs = await api.createWindow({
                'name': 'Documentation - ANNA-PALM',
                'type': 'ANNA-PALM-docs',
                'w':30, 'h':20,
                'data': {}
                })

  def abort(self):
    self.__abort = True

  async def load_model(self):
    if self.dialog is not None:
        self.dialog.close()

    workdirObj = await api.showFileDialog(type='directory', name="Please select your model folder (typically named `__model__`)", root=os.path.join(ROOT_DIR, "ANNA-PALM-MODELS"), engine=api.ENGINE_URL)

    if workdirObj:
        try:
            api.showStatus('Loading ANNA-PALM model ...')
            opt.load_dir = workdirObj.path
            self.model = create_model(opt)
            api.showStatus('ANNA-PALM model loaded!')

        except Exception as e:
            api.alert('Failed to load model, error: ' + str(e))

  async def train_sim_tubulin(self):
    if self.dialog is not None:
        self.dialog.close()
    opt.add_lr_channel = 'pseudo'
    opt.batchSize = 1
    opt.phase = 'train'
    api.showStatus('preparing data...')
    self.dash = await api.createWindow(type="Im2Im-Dashboard", name="ANNA-PALM Training", w=25, h=20, data={'display_mode':'one','metrics': ["discrim_loss", "gen_loss_GAN", "gen_loss", "gen_loss_L2", "gen_loss_SSIM", "squirrel_discrim_loss", "gen_loss_squirrel"], 'callbacks': ['onEpochEnd', 'onBatchEnd']})
    self.dash.onClose(self.abort)
    await self.dash.setLoading({'status_text': 'Preparing data...', 'loading': True})
    sources = create_data_sources(['TransformedTubulin001NB'], opt)
    d = sources['train']

    await self.dash.setLoading({'status_text': 'Start Training...', 'loading': True})
    await self.train(d, opt, model=self.model)
    #self.loop = asyncio.get_event_loop()
    #await asyncio.get_event_loop().run_in_executor(self.executor, self.train, d, opt)

  async def predict_sim_tubulin(self):
    if self.dialog is not None:
        self.dialog.close()
    opt.batchSize = 1
    opt.phase = 'test'
    opt.add_lr_channel = False
    api.showStatus('preparing data from ./tmp_predict')

    workdirObj = await api.showFileDialog(type='directory', name="Please select your data folder (contains `train` subfolder)")
    opt.workdir = workdirObj.path


    self.dash = await api.createWindow(type="Im2Im-Dashboard", name="ANNA-PALM Prediction", w=25, h=20, data={'display_mode':'one'})
    self.dash.onClose(self.abort)
    await self.dash.setLoading({'status_text': 'Preparing data...', 'loading': True})
    sources = create_data_sources(['TransformedTubulin001NB'], opt)
    d = sources['test']
    await self.dash.setLoading({'status_text': 'Start testing...', 'loading': True})
    await self.predict(d, opt, self.model)


  async def predict_csv(self):
    if self.dialog is not None:
        self.dialog.close()
    opt.batchSize = 1
    opt.phase = 'test'
    opt.add_lr_channel = False
    api.showStatus('preparing data from ./tmp_predict')

    workdirObj = await api.showFileDialog(type='directory', name="Please select your data folder (contains `train` subfolder)")
    opt.workdir = workdirObj.path

    self.dash = await api.createWindow(type="Im2Im-Dashboard", name="ANNA-PALM Prediction", w=25, h=20, data={'display_mode':'one'})
    self.dash.onClose(self.abort)
    await self.dash.setLoading({'status_text': 'Preparing data...', 'loading': True})
    sources = create_data_sources(['TransformedCSVImages'], opt)
    d = sources['test']
    await self.dash.setLoading({'status_text': 'Start testing...', 'loading': True})
    await self.predict(d, opt, self.model)

  async def train_csv(self):
    if self.dialog is not None:
        self.dialog.close()
    opt.batchSize = 1
    workdirObj = await api.showFileDialog(type='directory', name="Please select your data folder (contains `train` subfolder)")
    opt.workdir = workdirObj.path
    api.showStatus('preparing data from ', workdirObj.path)
    self.dash = await api.createWindow(type="Im2Im-Dashboard", name="ANNA-PALM Training", w=25, h=20, data={'display_mode':'one','metrics': ["discrim_loss", "gen_loss_GAN", "gen_loss", "gen_loss_L2", "gen_loss_SSIM", "squirrel_discrim_loss", "gen_loss_squirrel"], 'callbacks': ['onEpochEnd', 'onBatchEnd']})
    self.dash.onClose(self.abort)
    await self.dash.setLoading({'status_text': 'Preparing data...', 'loading': True})
    sources = create_data_sources(['TransformedCSVImages'], opt)
    d = sources['train']

    await self.dash.setLoading({'status_text': 'Start Training...', 'loading': True})
    await self.train(d, opt, model=self.model)

  def sendImages(self, images):
    displays = {}
    for k, v in images.items():
        for b in range(v.shape[0]):
            ima = v[b]
            channels = ima.shape[2]
            for i in range(channels):
                im = ima[:, :, i]
                im = Image.fromarray((im/im.max()*255).astype('uint8'))
                buffered = BytesIO()
                im.save(buffered, format="JPEG")
                img_str = base64.b64encode(buffered.getvalue()).decode('ascii')
                imgurl = 'data:image/png;base64,' + img_str
                name = k
                if v.shape[0]>1:
                    name += '_b'+str(b)
                if channels>1:
                    name += '_c'+str(i)
                displays[name] = imgurl
                # api.createWindow(name=str(k)+str(b)+str(i) , type='imjoy/image', w=12, h=15, data={"src": imgurl})
    self.dash.appendDisplay('Step ' + str(self.step), displays)

  async def train(self, dataset, opt, steps=1000, model=None):
    #asyncio.set_event_loop(self.loop)
    self.__abort = False

    api.showStatus('start training...')
    if model is None:
        model = create_model(opt)
    self.step = 0
    def step_callback(model, details):
        self.step += 1
        if self.step<3:
            self.dash.setLoading({'status_text': 'Start Training...', 'loading': False})
        try:
            if 'display' in details:
                images = details['display']
                del details['display']
                self.sendImages(images)
            api.showStatus('training: ' + str(details))
            api.log(str(details))
            api.progress(self.step/steps)
            print(details)
            self.dash.updateCallback('onEpochEnd', self.step, details)
            print(str(details))
            sys.stdout.flush()
        except:
            print('step callback error')
        if self.__abort:
            return 'stop'

    model.train(dataset, step_callback=step_callback, verbose=1, max_steps=steps)

  async def predict(self, dataset, opt, model=None):
    if model is None:
        model = create_model(opt)

    self.step = 0
    def step_callback(model, details):
        self.step += 1
        if self.step<3:
            self.dash.setLoading({'status_text': 'Start prediction...', 'loading': False})
        try:
            if 'display' in details:
                images = details['display']
                del details['display']
                self.sendImages(images)
            api.showStatus('predicting: ' + str(details))
            print(str(details))
            api.log(str(details))
            sys.stdout.flush()
        except:
            print('step callback error')
    model.predict(dataset, step_callback=step_callback, verbose=1)

api.export(ImJoyPlugin())
</script>
